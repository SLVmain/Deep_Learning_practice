{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HW_19_sec2sec.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SLVmain/Deep_Learning_practice/blob/main/HW_19_sec2sec.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xhGFfIoFzgSc"
      },
      "source": [
        "# Добро пожаловать на задание уровня Pro.\n",
        "Необходимо написать чат-бота, используя модель seq2seq.\n",
        "\n",
        "Ссылка на базу https://storage.yandexcloud.net/aiueducation/Content/advanced/l3/9kdialogs.txt\n",
        "\n",
        "База содержит примеры пар: вопрос-ответ. По аналогии с моделью преводчика (англ - рус), создайте чат-бота (вопрос - ответ)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Подключим модуль для загрузки файлов в colab\n",
        "from google.colab import files\n",
        "\n",
        "# Подключим модуль numpy для работы с массивами\n",
        "import numpy as np\n",
        "\n",
        "# Подгрузим модели кераса\n",
        "from tensorflow.keras.models import Model, load_model\n",
        "\n",
        "# Подключим нужные слои\n",
        "from tensorflow.keras.layers import Dense, Embedding, LSTM, Input\n",
        "\n",
        "# Поключим оптимайзеры\n",
        "from tensorflow.keras.optimizers import RMSprop, Adadelta\n",
        "\n",
        "# Подключим метод ограничения последовательности заданной длиной\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Подключим токенайзер\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "\n",
        "# Подключим модуль для one hot кодировки\n",
        "from tensorflow.keras import utils\n",
        "\n",
        "# Подключим визуализацию графа модели\n",
        "from tensorflow.keras.utils import plot_model\n",
        "\n",
        "# Подключим модуль для работы с yaml - файлами\n",
        "import yaml\n",
        "\n",
        "import gdown"
      ],
      "metadata": {
        "id": "7vC64ctRVhT2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gdown.download('https://storage.yandexcloud.net/aiueducation/Content/advanced/l3/9kdialogs.txt', None, quiet=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Qp9F7_DfHLyi",
        "outputId": "a01655e3-5d3f-48aa-8de1-033b120b6bc1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'9kdialogs.txt'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"9kdialogs.txt\", 'r', encoding='utf-8') as f: # Открываем файл словаря в режиме чтения\n",
        "    lines = f.read().split('\\n')                 # Читаем весь файл, режем на строки\n",
        "\n",
        "# Цикл по строкам\n",
        "lines_copy = lines.copy()\n",
        "for i,line in enumerate(lines):\n",
        "    if line == '':\n",
        "      lines_copy.remove(line)"
      ],
      "metadata": {
        "id": "rRSkVBOHMLjd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(lines_copy))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LUvUrYO2O4Q_",
        "outputId": "08877569-6aa6-4221-9112-14e0478e7c74"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "19828\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#print(questions[0].replace('- - ', ''))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l_QFLjGeZ_L4",
        "outputId": "99dcd56c-9c86-4bed-f19c-4a182efbfb1c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "﻿Как вы можете быть таким уверенным?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def my_replacer(s):  \n",
        "\n",
        "    ''' Функция для удаления пробелов перед знаками препинания\n",
        "\n",
        "        Args: строка или список строк\n",
        "\n",
        "        Returns: строка или список строк\n",
        "    '''\n",
        "\n",
        "    if isinstance(s,str): # Если получили строку\n",
        "\n",
        "        # Убираем перед знаками препинания пробел и возвращаем\n",
        "        return s.replace(' .','.').replace(' ,',',').replace(' !','!').replace(' ?','?').replace('- - ', '').strip(' - -').strip('- - ').strip('-').strip('- -').lower()\n",
        "\n",
        "    if isinstance(s,list): # Если получили список\n",
        "        ou=[]              # Заготовим пустой список\n",
        "\n",
        "        for l in s:        # Цикл по строкам из списка\n",
        "            ou.append(l.replace(' .','.').replace(' ,',',').replace(' !','!').replace(' ?','?').replace('- - ', '').strip(' - -').strip('- - ').strip('-').strip('- -').lower()) # Убираем перед знаками препинания пробел и возвращаем\n",
        "\n",
        "        # Вернем список строк\n",
        "        return ou    "
      ],
      "metadata": {
        "id": "RDbKr5qwTrwL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "questions = [] # Переменная для списка входных фраз\n",
        "answers = []   # Переменная для списка ответных фраз                              \n",
        "for i in range(0, len(lines_copy), 2):\n",
        "  try:\n",
        "      questions.append(my_replacer(lines_copy[i]))\n",
        "      answers.append(my_replacer(lines_copy[i+1]))\n",
        "  except:\n",
        "      continue                                    "
      ],
      "metadata": {
        "id": "WS9VoblkN62y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Добавим в каждую ответную фразу теги  <START> и <END>\n",
        "answers = ['<START> ' + s + ' <END>' for s in answers]\n",
        "\n",
        "# Выведем обновленные данные на экран\n",
        "print('Вопрос : {}'.format(questions[111])) # Пример входной фразы\n",
        "print('Ответ : {}'.format(answers[111]))    # Пример ответной фразы"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SNrO_h7JVDeL",
        "outputId": "187783ab-25f3-43ef-df40-d27e24218f4f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Вопрос : больно?\n",
            "Ответ : <START> немного. <END>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(0,10):\n",
        "  print(i, questions[i], answers[i])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AbsOK362Sxe-",
        "outputId": "49099ce1-9b07-45eb-d04d-245f33a331eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 ﻿как вы можете быть таким уверенным? <START> элементарно. <END>\n",
            "1 а что делать будем? <START> ждать. <END>\n",
            "2 надеюсь, не до первой звезды? <START> я тоже на это надеюсь. <END>\n",
            "3 за что? <START> вы знаете за что! <END>\n",
            "4 ты что-нибудь понимаешь? <START> абсолютно ничего. <END>\n",
            "5 обсудим это завтра, ладно? <START> хорошо. <END>\n",
            "6 кто услышит? <START> кто-кто..ну твой следователь. <END>\n",
            "7 что - если? <START> так, ничего. <END>\n",
            "8 ну я пойду? <START> а? иди, иди. постой... <END>\n",
            "9 может, стоило ее предупредить? <START> может. <END>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(questions) == len(answers)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xw08H3rQVPlw",
        "outputId": "41b3bac7-992a-4193-899d-3a7bb7fe9c6b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Создадим токенайзер \n",
        "tokenizer = Tokenizer(oov_token='unknown', filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n',split=' ') \n",
        "\n",
        "# Загружаем в токенизатор список фраз для сборки словаря частотности\n",
        "tokenizer.fit_on_texts(questions + answers)         \n",
        "\n",
        "# Список с cодержимым словаря\n",
        "vocabularyItems = list(tokenizer.word_index.items())    \n",
        "\n",
        "# Размер словаря\n",
        "vocabularySize = len(vocabularyItems)+1        \n",
        "\n",
        "# Выведем фрагмент и размер словаря\n",
        "print( 'Фрагмент словаря : {}'.format(vocabularyItems[:50]))       \n",
        "print( 'Размер словаря : {}'.format(vocabularySize))         "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P2u4hqUUVWrg",
        "outputId": "b9a372b6-20b7-4289-bbd0-3bcf975e948d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Фрагмент словаря : [('unknown', 1), ('start', 2), ('end', 3), ('что', 4), ('не', 5), ('ты', 6), ('а', 7), ('я', 8), ('в', 9), ('да', 10), ('это', 11), ('вы', 12), ('как', 13), ('нет', 14), ('и', 15), ('ну', 16), ('где', 17), ('на', 18), ('у', 19), ('с', 20), ('кто', 21), ('так', 22), ('же', 23), ('он', 24), ('то', 25), ('все', 26), ('мне', 27), ('куда', 28), ('чего', 29), ('там', 30), ('меня', 31), ('есть', 32), ('тебя', 33), ('вас', 34), ('за', 35), ('тебе', 36), ('еще', 37), ('знаю', 38), ('вам', 39), ('мы', 40), ('почему', 41), ('ничего', 42), ('здесь', 43), ('может', 44), ('она', 45), ('конечно', 46), ('можно', 47), ('чем', 48), ('его', 49), ('зачем', 50)]\n",
            "Размер словаря : 11408\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Разбиваем текст входных фраз на последовательности индексов\n",
        "tokenizedQuestions = tokenizer.texts_to_sequences(questions)\n",
        "\n",
        "# Уточняем длину самой длинной фразы\n",
        "maxLenQuestions = max([ len(x) for x in tokenizedQuestions])\n",
        "\n",
        "# Делаем последовательности одной длины, заполняя нулями более короткие фразы\n",
        "paddedQuestions = pad_sequences(tokenizedQuestions, maxlen=maxLenQuestions, padding='post')\n",
        "\n",
        "# Предподготавливаем данные для входа в сеть, переводим в numpy массив\n",
        "encoderForInput = np.array(paddedQuestions)        \n",
        "\n",
        "# Выведем на экран\n",
        "print('Пример входной фразы                         : {}'.format(questions[10]))         \n",
        "print('Пример кодированной входной фразу            : {}'.format(encoderForInput[10]))  \n",
        "print('Размеры закодированного массива входных фраз : {}'.format(encoderForInput.shape))  \n",
        "print('Установленная длина входных фраз             : {}'.format(maxLenQuestions))        "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5tbnOnivWOtw",
        "outputId": "7e0a8b6b-1400-43d5-9fae-aba6167eb4f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Пример входной фразы                         : а вы тут, что ли, не одна живете?\n",
            "Пример кодированной входной фразу            : [  7  12  60   4  53   5 264 946   0   0   0]\n",
            "Размеры закодированного массива входных фраз : (9914, 11)\n",
            "Установленная длина входных фраз             : 11\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Разбиваем текст ответных фраз на последовательности индексов\n",
        "tokenizedAnswers = tokenizer.texts_to_sequences(answers) \n",
        "\n",
        "# Уточняем длину самого длинного ответа\n",
        "maxLenAnswers = max([len(x) for x in tokenizedAnswers])\n",
        "\n",
        "# Делаем последовательности одной длины, заполняя нулями более ответы\n",
        "paddedAnswers = pad_sequences(tokenizedAnswers, maxlen=maxLenAnswers, padding='post')\n",
        "\n",
        "# Предподготавливаем данные для входа в сеть, переводим в numpy массив\n",
        "decoderForInput = np.array(paddedAnswers)               \n",
        "\n",
        "# Выведем на экран\n",
        "print('Пример оригинального ответа на вход: {}'.format(answers[100]))                         \n",
        "print('Пример кодированного ответа на вход : {}'.format(decoderForInput[100][:30]))           \n",
        "print('Размеры кодированного массива ответов на вход : {}'.format(decoderForInput.shape))     \n",
        "print('Установленная длина ответов на вход : {}'.format(maxLenAnswers))        "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rKe0q8wabf_h",
        "outputId": "ca3753e4-a953-4467-f604-6fafe3b52eab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Пример оригинального ответа на вход: <START> да, вроде, ничего особенного. <END>\n",
            "Пример кодированного ответа на вход : [  2  10 172  42 481   3   0   0   0   0   0   0   0   0]\n",
            "Размеры кодированного массива ответов на вход : (9914, 14)\n",
            "Установленная длина ответов на вход : 14\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Разбиваем текст ответов на последовательности индексов\n",
        "tokenizedAnswers = tokenizer.texts_to_sequences(answers) \n",
        "\n",
        "for i in range(len(tokenizedAnswers)) :                  # Для разбитых на последовательности ответов\n",
        "    tokenizedAnswers[i] = tokenizedAnswers[i][1:]          # Избавляемся от тега <START>\n",
        "\n",
        "# Делаем последовательности одной длины, заполняя нулями более короткие ответы\n",
        "paddedAnswers = pad_sequences(tokenizedAnswers, maxlen=maxLenAnswers , padding='post') \n",
        "\n",
        "# И сохраняем в виде массива numpy\n",
        "decoderForOutput = np.array(paddedAnswers)     "
      ],
      "metadata": {
        "id": "zfjFkIhSblou"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Выведем на экран\n",
        "\n",
        "print('Пример кодированного ответа на вход : {}'.format(decoderForInput[100][:21]))   \n",
        "print('Пример кодированного ответа на выход : {}'.format(decoderForOutput[100][:21]))\n",
        "print('Размеры кодированного массива ответов на выход : {}'.format(decoderForOutput.shape))  \n",
        "print('Установленная длина вопросов на выход : {}'.format(maxLenAnswers))                    "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m7JovxZZbqdN",
        "outputId": "33aca04a-e3bf-4801-8368-257da1734d1e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Пример кодированного ответа на вход : [  2  10 172  42 481   3   0   0   0   0   0   0   0   0]\n",
            "Пример кодированного ответа на выход : [ 10 172  42 481   3   0   0   0   0   0   0   0   0   0]\n",
            "Размеры кодированного массива ответов на выход : (9914, 14)\n",
            "Установленная длина вопросов на выход : 14\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qDNMte7cns1A"
      },
      "source": [
        "# Создадим энкодер \n",
        "\n",
        "encoderInputs = Input(shape=(None , ))                                             # Добавим входной слой\n",
        "encoderEmbedding = Embedding(vocabularySize, 200 , mask_zero=True)(encoderInputs)  # Добавим эмбеддинг\n",
        "encoderOutputs, state_h , state_c = LSTM(200, return_state=True)(encoderEmbedding) # Добавим LSTM\n",
        "encoderStates = [state_h, state_c]                                                 # Соберем выходы lstm  в список    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0y9Y9ZqrnwLu"
      },
      "source": [
        "# Создадим декодер \n",
        "\n",
        "decoderInputs = Input(shape=(None, ))                                                # Добавим входной слой\n",
        "decoderEmbedding = Embedding(vocabularySize, 200, mask_zero=True) (decoderInputs)    # Добавим эмбеддинг\n",
        "decoderLSTM = LSTM(200, return_state=True, return_sequences=True)                    # Создадим LSTM слой\n",
        "decoderOutputs , _ , _ = decoderLSTM (decoderEmbedding, initial_state=encoderStates) # Прогоним выход embedding через LSTM\n",
        "decoderDense = Dense(vocabularySize, activation='softmax')                           # Создадим dense слой\n",
        "output = decoderDense (decoderOutputs)                                               # Прогоним  выход LSTM через DENSE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-nUYagRLnwko"
      },
      "source": [
        "# Собираем модель\n",
        "\n",
        "model = Model([encoderInputs, decoderInputs], output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FLDHVdcIoltf"
      },
      "source": [
        "# Компилиуем модель\n",
        "\n",
        "model.compile(optimizer=RMSprop(), loss='sparse_categorical_crossentropy')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "usHiPpGzojZ9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "44344d88-4d03-4b50-e0df-65bf8449d6c0"
      },
      "source": [
        "# Выведем на экран информацию о построенной модели нейросети\n",
        "\n",
        "print(model.summary())  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_4\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_7 (InputLayer)           [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " input_8 (InputLayer)           [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " embedding_4 (Embedding)        (None, None, 200)    2281600     ['input_7[0][0]']                \n",
            "                                                                                                  \n",
            " embedding_5 (Embedding)        (None, None, 200)    2281600     ['input_8[0][0]']                \n",
            "                                                                                                  \n",
            " lstm_4 (LSTM)                  [(None, 200),        320800      ['embedding_4[0][0]']            \n",
            "                                 (None, 200),                                                     \n",
            "                                 (None, 200)]                                                     \n",
            "                                                                                                  \n",
            " lstm_5 (LSTM)                  [(None, None, 200),  320800      ['embedding_5[0][0]',            \n",
            "                                 (None, 200),                     'lstm_4[0][1]',                 \n",
            "                                 (None, 200)]                     'lstm_4[0][2]']                 \n",
            "                                                                                                  \n",
            " dense_2 (Dense)                (None, None, 11408)  2293008     ['lstm_5[0][0]']                 \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 7,497,808\n",
            "Trainable params: 7,497,808\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HqM1TJgUogeF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 466
        },
        "outputId": "4e87fff7-ca68-4a8b-9949-ce4f6b1fe0bc"
      },
      "source": [
        "# Построим график для визуализации слоев и связей между ними\n",
        "\n",
        "plot_model(model, to_file='model.png')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Image object>"
            ],
            "image/png": "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\n"
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UvT72V_0bpCN"
      },
      "source": [
        "Пора обучаться. И не забудем сохранить обученную модель на диске"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WcT0PuS9nysP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "12848c7e-7de6-4a09-f61e-561311a5b3e9"
      },
      "source": [
        "# Запустим обучение\n",
        "model.fit([encoderForInput , decoderForInput], decoderForOutput, batch_size=256, epochs=30) \n",
        "\n",
        "# Сохраним модель на диске\n",
        "model.save( 'content/model_30epochs(rms).h5' )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "39/39 [==============================] - 1s 29ms/step - loss: 0.5652\n",
            "Epoch 2/30\n",
            "39/39 [==============================] - 1s 29ms/step - loss: 0.5506\n",
            "Epoch 3/30\n",
            "39/39 [==============================] - 1s 29ms/step - loss: 0.5358\n",
            "Epoch 4/30\n",
            "39/39 [==============================] - 1s 29ms/step - loss: 0.5213\n",
            "Epoch 5/30\n",
            "39/39 [==============================] - 1s 29ms/step - loss: 0.5064\n",
            "Epoch 6/30\n",
            "39/39 [==============================] - 1s 29ms/step - loss: 0.4924\n",
            "Epoch 7/30\n",
            "39/39 [==============================] - 1s 29ms/step - loss: 0.4785\n",
            "Epoch 8/30\n",
            "39/39 [==============================] - 1s 29ms/step - loss: 0.4650\n",
            "Epoch 9/30\n",
            "39/39 [==============================] - 1s 29ms/step - loss: 0.4517\n",
            "Epoch 10/30\n",
            "39/39 [==============================] - 1s 29ms/step - loss: 0.4375\n",
            "Epoch 11/30\n",
            "39/39 [==============================] - 1s 29ms/step - loss: 0.4259\n",
            "Epoch 12/30\n",
            "39/39 [==============================] - 1s 28ms/step - loss: 0.4121\n",
            "Epoch 13/30\n",
            "39/39 [==============================] - 1s 29ms/step - loss: 0.3998\n",
            "Epoch 14/30\n",
            "39/39 [==============================] - 1s 29ms/step - loss: 0.3889\n",
            "Epoch 15/30\n",
            "39/39 [==============================] - 1s 29ms/step - loss: 0.3755\n",
            "Epoch 16/30\n",
            "39/39 [==============================] - 1s 29ms/step - loss: 0.3635\n",
            "Epoch 17/30\n",
            "39/39 [==============================] - 1s 29ms/step - loss: 0.3524\n",
            "Epoch 18/30\n",
            "39/39 [==============================] - 1s 29ms/step - loss: 0.3413\n",
            "Epoch 19/30\n",
            "39/39 [==============================] - 1s 29ms/step - loss: 0.3299\n",
            "Epoch 20/30\n",
            "39/39 [==============================] - 1s 29ms/step - loss: 0.3192\n",
            "Epoch 21/30\n",
            "39/39 [==============================] - 1s 28ms/step - loss: 0.3091\n",
            "Epoch 22/30\n",
            "39/39 [==============================] - 1s 29ms/step - loss: 0.2982\n",
            "Epoch 23/30\n",
            "39/39 [==============================] - 1s 29ms/step - loss: 0.2885\n",
            "Epoch 24/30\n",
            "39/39 [==============================] - 1s 29ms/step - loss: 0.2788\n",
            "Epoch 25/30\n",
            "39/39 [==============================] - 1s 29ms/step - loss: 0.2698\n",
            "Epoch 26/30\n",
            "39/39 [==============================] - 1s 29ms/step - loss: 0.2596\n",
            "Epoch 27/30\n",
            "39/39 [==============================] - 1s 29ms/step - loss: 0.2510\n",
            "Epoch 28/30\n",
            "39/39 [==============================] - 1s 29ms/step - loss: 0.2421\n",
            "Epoch 29/30\n",
            "39/39 [==============================] - 1s 29ms/step - loss: 0.2342\n",
            "Epoch 30/30\n",
            "39/39 [==============================] - 1s 29ms/step - loss: 0.2251\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LQpGBXUNvfGC"
      },
      "source": [
        "# Сохраним веса модели\n",
        "model.save_weights('s2s_30epochs.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2pbCDz6In033"
      },
      "source": [
        "def makeInferenceModels():\n",
        "\n",
        "    ''' Функция сборки сети для перевода фраз из уже обученных слов\n",
        "\n",
        "        Args: -\n",
        "\n",
        "        Returns: модели энкодера и декодера   \n",
        "    '''    \n",
        "\n",
        "    # Создадим модель кодера, на входе далее будут закодированные вопросы, на выходе состояния state_h, state_c\n",
        "    encoderModel = Model(encoderInputs, encoderStates) \n",
        "\n",
        "    # Создадим модель декодера\n",
        "    decoderStateInput_h = Input(shape=(200 ,)) # Добавим входной слой для state_h\n",
        "    decoderStateInput_c = Input(shape=(200 ,)) # Добавим входной слой для state_c\n",
        "\n",
        "    # Соберем оба inputs вместе и запишем в decoderStatesInputs\n",
        "    decoderStatesInputs = [decoderStateInput_h, decoderStateInput_c] \n",
        "\n",
        "    # Берём ответы, прошедшие через эмбединг, вместе с состояниями и подаём LSTM cлою\n",
        "    decoderOutputs, state_h, state_c = decoderLSTM(decoderEmbedding, initial_state=decoderStatesInputs) \n",
        "    \n",
        "    # LSTM даст нам новые состояния\n",
        "    decoderStates = [state_h, state_c]            \n",
        "    \n",
        "    # И ответы, которые мы пропустим через полносвязный слой с софтмаксом\n",
        "    decoderOutputs = decoderDense(decoderOutputs) \n",
        "\n",
        "    # Определим модель декодера, на входе далее будут раскодированные ответы (decoderForInputs) и состояния\n",
        "    # на выходе предсказываемый ответ и новые состояния\n",
        "    decoderModel = Model([decoderInputs] + decoderStatesInputs, [decoderOutputs] + decoderStates)\n",
        "\n",
        "    # Вернем рабочие модели энкодера и декодера  \n",
        "    return encoderModel , decoderModel"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fzsCtJfFn261"
      },
      "source": [
        "def strToTokens(sentence: str):      \n",
        "\n",
        "    ''' Функция для удаления пробелов перед знаками препинания\n",
        "\n",
        "        Args: фраза\n",
        "\n",
        "        Returns: список токенов\n",
        "    '''\n",
        "\n",
        "    # Почистим фразу\n",
        "    tmp_sent = my_replacer(sentence)  \n",
        "    \n",
        "    # Приведем предложение к нижнему регистру и разбирает на слова\n",
        "    words = tmp_sent.lower().split()  \n",
        "    \n",
        "    # Создадим список для последовательности токенов/индексов\n",
        "    tokensList = list()               \n",
        "\n",
        "    # Для каждого слова в предложении\n",
        "    for word in words:\n",
        "        \n",
        "        try:\n",
        "            tokensList.append(tokenizer.word_index[word]) # Определяем токенайзером индекс и добавляем в список\n",
        "        except:\n",
        "            pass # Слова нет - просто игнорируем его\n",
        "\n",
        "    # Вернёт входную фразу в виде последовательности индексов\n",
        "    if tokensList:\n",
        "        return pad_sequences([tokensList], maxlen=maxLenQuestions , padding='post')\n",
        "\n",
        "    # Фраза из незнакомых слов - вернем None \n",
        "    return None"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PXtp9Yc1dHWm"
      },
      "source": [
        "Запускаем функцию для построения модели кодера и декодера"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8FLuVC7XsIGI"
      },
      "source": [
        "encModel , decModel = makeInferenceModels() "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9B9sAeCNM8UQ",
        "outputId": "8ede683b-bd94-480c-b088-cf6df868b26f"
      },
      "source": [
        "# Цикл по количеству входных фраз - их 6\n",
        "\n",
        "for _ in range(6):\n",
        "\n",
        "    # подготовка\n",
        "    \n",
        "    qua  = strToTokens(input('Задайте мне вопрос: '))\n",
        "    if qua is None:                                      \n",
        "        print (\"а вот спросите меня о чем-нить полезном: \")  # Выдадим дежурную фразу\n",
        "        continue                                             # Пойдем за следущей фразой\n",
        "\n",
        "    emptyTargetSeq = np.zeros((1, 1))                    \n",
        "    emptyTargetSeq[0, 0] = tokenizer.word_index['start'] \n",
        "    stopCondition = False                                \n",
        "    decodedTranslation = '' \n",
        "    statesValues = encModel.predict(qua)                              \n",
        "\n",
        "    # пока не сработало стоп-условие\n",
        "    while not stopCondition:                             \n",
        "\n",
        "        # В модель декодера подадим пустую последовательность со словом 'start' и состояния\n",
        "        decOutputs , h , c = decModel.predict([emptyTargetSeq] + statesValues)\n",
        "        # Получим индекс предсказанного слова.\n",
        "        sampledWordIndex = np.argmax( decOutputs[0, 0, :]) \n",
        "        # Создаем переменную для преобразованных на естественный язык слов\n",
        "        sampledWord = None                                 \n",
        "\n",
        "        # Переберем в цикле все индексы токенайзера\n",
        "        for word, index in tokenizer.word_index.items():\n",
        "        \n",
        "            # Если индекс выбранного слова соответствует какому-то индексу из словаря\n",
        "            if sampledWordIndex == index:              \n",
        "                # Слово, идущее под этим индексом в словаре, добавляется в итоговый ответ \n",
        "                decodedTranslation += ' {}'.format(word) \n",
        "                # Выбранное слово фиксируем в переменную sampledWord\n",
        "                sampledWord = word                       \n",
        "        \n",
        "        # Если выбранным словом оказывается 'end' либо если сгенерированный ответ превышает заданную максимальную длину ответа\n",
        "        if sampledWord == 'end' or len(decodedTranslation.split()) > maxLenAnswers:\n",
        "            stopCondition = True # Срабатывает стоп-условие и прекращаем генерацию\n",
        "\n",
        "        # Создаем пустой массив\n",
        "        emptyTargetSeq = np.zeros((1, 1))       \n",
        "        \n",
        "        # Заносим в него индекс выбранного слова\n",
        "        emptyTargetSeq[0, 0] = sampledWordIndex \n",
        "        \n",
        "        # Записываем состояния, обновленные декодером \n",
        "        statesValues = [h, c]   \n",
        "\n",
        "        # И продолжаем цикл с обновленными параметрами                \n",
        "                                                \n",
        "    # Выводим ответ сгенерированный декодером\n",
        "    print(\"Ответ: \", decodedTranslation[:-4]) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Задайте мне вопрос: кто ты\n",
            "Ответ:   я\n",
            "Задайте мне вопрос: почему ты съел курицу\n",
            "Ответ:   покориться судьбе\n",
            "Задайте мне вопрос: какой поезд завтра\n",
            "Ответ:   когда\n",
            "Задайте мне вопрос: есть места?\n",
            "Ответ:   а кто\n",
            "Задайте мне вопрос: пойдем гулять?\n",
            "Ответ:   ну\n",
            "Задайте мне вопрос: какая погода сегодня?\n",
            "Ответ:   не знаю\n"
          ]
        }
      ]
    }
  ]
}